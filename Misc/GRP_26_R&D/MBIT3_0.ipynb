{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#necessary\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#NPL\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "#Ml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tVyLRcJJOng",
        "outputId": "b59190e3-73ab-486e-e0f4-4e190e1046bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btsVAiVHI4rZ",
        "outputId": "6ff377b0-600b-470b-96a4-e5e1fd240976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('/content/drive/MyDrive/MBIT_data/mbti_1.csv')\n",
        "data=df2.copy()"
      ],
      "metadata": {
        "id": "ZaynjdKFI90e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "xiyHCE9PJAzr",
        "outputId": "f80ac6ec-1369-48f4-888a-9b13396f04e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        type                                              posts\n",
              "count   8675                                               8675\n",
              "unique    16                                               8675\n",
              "top     INFP  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
              "freq    1832                                                  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efbdd9c2-f70d-4a30-a7f7-98bf2e51d90e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8675</td>\n",
              "      <td>8675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>16</td>\n",
              "      <td>8675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1832</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efbdd9c2-f70d-4a30-a7f7-98bf2e51d90e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-efbdd9c2-f70d-4a30-a7f7-98bf2e51d90e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-efbdd9c2-f70d-4a30-a7f7-98bf2e51d90e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33c16f87-9ec0-4452-b0bb-329412c9bf88\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33c16f87-9ec0-4452-b0bb-329412c9bf88')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33c16f87-9ec0-4452-b0bb-329412c9bf88 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          16,\n          \"1832\",\n          \"8675\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"posts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"8675\",\n          \"'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait... I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can. Don't worry, people will always be around to...|||Yo entp ladies... if you're into a complimentary personality,well, hey.|||... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as...|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own... like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm... yep.|||Ahh... old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too...|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.'\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Count the occurrences of each type\n",
        "cnt_srs = df2['type'].value_counts()\n",
        "\n",
        "# Set the size of the plot\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Create the bar plot\n",
        "sns.barplot(x=cnt_srs.index, y=cnt_srs.values, alpha=0.8)\n",
        "\n",
        "# Set the labels of the plot\n",
        "plt.xlabel('Personality Types', fontsize=12)\n",
        "plt.ylabel('Number of Posts Available', fontsize=12)\n",
        "plt.title('Distribution of Posts by Personality Type', fontsize=15)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "2wSCP0g2JMn-",
        "outputId": "6cf5d2fb-6aea-4ca4-97f8-4dbff1d686ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MBTI unique types and binary translation dictionaries\n",
        "unique_type_list = ['infj', 'entp', 'intp', 'intj', 'entj', 'enfj', 'infp', 'enfp', 'istp', 'isfp', 'isfj', 'istj', 'estp', 'esfp', 'estj', 'esfj']\n",
        "b_Pers = {'I': 0, 'E': 1, 'N': 0, 'S': 1, 'F': 0, 'T': 1, 'J': 0, 'P': 1}\n",
        "b_Pers_list = [{0: 'I', 1: 'E'}, {0: 'N', 1: 'S'}, {0: 'F', 1: 'T'}, {0: 'J', 1: 'P'}]\n",
        "\n",
        "def translate_personality(personality):\n",
        "    # Transform mbti to binary vector\n",
        "    return [b_Pers[l] for l in personality]\n",
        "\n",
        "# To show result output for personality prediction\n",
        "def translate_back(personality):\n",
        "    # Transform binary vector to mbti personality\n",
        "    s = \"\"\n",
        "    for i, l in enumerate(personality):\n",
        "        s += b_Pers_list[i][l]\n",
        "    return s\n"
      ],
      "metadata": {
        "id": "E7JeBmISNqWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wTiWTA2ZOJxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define stop words and lemmatizer\n",
        "useless_words = set(stopwords.words('english'))\n",
        "lemmatiser = WordNetLemmatizer()\n",
        "\n",
        "data = df2.copy()\n",
        "\n",
        "def pre_process_text(data, remove_stop_words=True, remove_mbti_profiles=True):\n",
        "    list_personality = []\n",
        "    list_posts = []\n",
        "    len_data = len(data)\n",
        "    i = 0\n",
        "\n",
        "    for row in data.iterrows():\n",
        "        # check code working\n",
        "        # i+=1\n",
        "        # if (i % 500 == 0 or i == 1 or i == len_data):\n",
        "        #     print(\"%s of %s rows\" % (i, len_data))\n",
        "\n",
        "        # Remove and clean comments\n",
        "        posts = row[1].posts\n",
        "\n",
        "        # Remove url links\n",
        "        temp = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', posts)\n",
        "\n",
        "        # Remove Non-words - keep only words\n",
        "        temp = re.sub(\"[^a-zA-Z]\", \" \", temp)\n",
        "\n",
        "        # Remove spaces > 1\n",
        "        temp = re.sub(' +', ' ', temp).lower()\n",
        "\n",
        "        # Remove multiple letter repeating words\n",
        "        temp = re.sub(r'([a-z])\\1{2,}[\\s|\\w]*', '', temp)\n",
        "\n",
        "        # Remove stop words\n",
        "        if remove_stop_words:\n",
        "            temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ') if w not in useless_words])\n",
        "        else:\n",
        "            temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ')])\n",
        "\n",
        "        # Remove MBTI personality words from posts\n",
        "        if remove_mbti_profiles:\n",
        "            for t in unique_type_list:\n",
        "                temp = temp.replace(t, \"\")\n",
        "\n",
        "        # Transform mbti to binary vector\n",
        "        type_labelized = translate_personality(row[1].type)  # or use lab_encoder.transform([row[1].type])[0]\n",
        "        list_personality.append(type_labelized)\n",
        "        # The cleaned data temp is passed here\n",
        "        list_posts.append(temp)\n",
        "\n",
        "    # Returns the result\n",
        "    list_posts = np.array(list_posts)\n",
        "    list_personality = np.array(list_personality)\n",
        "    return list_posts, list_personality\n",
        "\n",
        "list_posts, list_personality = pre_process_text(data, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "print(\"Example:\")\n",
        "print(\"\\nPost before preprocessing:\\n\\n\", data.posts.iloc[0])\n",
        "print(\"\\nPost after preprocessing:\\n\\n\", list_posts[0])\n",
        "print(\"\\nMBTI before preprocessing:\\n\\n\", data.type.iloc[0])\n",
        "print(\"\\nMBTI after preprocessing:\\n\\n\", list_personality[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qi5x25eODfL",
        "outputId": "c76cb48b-2955-4fe4-9af0-a0152196b01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example:\n",
            "\n",
            "Post before preprocessing:\n",
            "\n",
            " 'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait... I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can. Don't worry, people will always be around to...|||Yo entp ladies... if you're into a complimentary personality,well, hey.|||... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as...|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own... like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm... yep.|||Ahh... old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too...|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.'\n",
            "\n",
            "Post after preprocessing:\n",
            "\n",
            "    moment sportscenter top ten play prank life changing experience life repeat today may perc experience immerse last thing  friend posted facebook committing suicide next day rest peace hello  sorry hear distress natural relationship perfection time every moment existence try figure hard time time growth welcome stuff game set match prozac wellbrutin least thirty minute moving leg mean moving sitting desk chair weed moderation maybe try edible healthier alternative basically come three item determined type whichever type want would likely use given type cognitive function whatnot left thing moderation sims indeed video game good one note good one somewhat subjective completely promoting death given sim dear  favorite video game growing current favorite video game cool appears late sad someone everyone wait thought confidence good thing cherish time solitude b c revel within inner world whereas time workin enjoy time worry people always around yo  lady complimentary personality well hey main social outlet xbox live conversation even verbally fatigue quickly really dig part banned thread requires get high backyard roast eat marshmellows backyard conversing something intellectual followed massage kiss banned many b sentence could think b banned watching movie corner dunce banned health class clearly taught nothing peer pressure banned whole host reason two baby deer left right munching beetle middle using blood two caveman diary today latest happening designated cave diary wall see pokemon world  society everyone becomes optimist artist artist draw idea count forming something like signature welcome robot rank person downed self esteem cuz avid signature artist like proud banned taking room bed ya gotta learn share roach banned much thundering grumbling kind storm yep ahh old high school music heard age failed public speaking class year ago sort learned could better position big part failure overloading like person mentality confirmed  way move denver area start new life \n",
            "\n",
            "MBTI before preprocessing:\n",
            "\n",
            " INFJ\n",
            "\n",
            "MBTI after preprocessing:\n",
            "\n",
            " [0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nRow, nCol = list_personality.shape\n",
        "print(f'No. of posts = {nRow}  and No. of Personalities = {nCol} ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xjPhHJTOmze",
        "outputId": "143d6c40-7fe3-499c-ea25-24159f1a78f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of posts = 8675  and No. of Personalities = 4 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Define the vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    analyzer=\"word\",\n",
        "    max_features=1000,\n",
        "    max_df=0.7,\n",
        "    min_df=0.1\n",
        ")\n",
        "\n",
        "# Fit and transform the list_posts directly to a TF-IDF representation\n",
        "print(\"Using TfidfVectorizer:\")\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(list_posts)\n",
        "\n",
        "# The shape of the TF-IDF matrix\n",
        "print(\"Now the dataset size is as below\")\n",
        "print(X_tfidf.shape)\n",
        "\n",
        "# Feature names\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "print(\"10 feature names can be seen below\")\n",
        "print(list(enumerate(feature_names[:10])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzHztDzRO0i-",
        "outputId": "b95ea61d-7725-4c80-a4a3-bc21787d6b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TfidfVectorizer:\n",
            "Now the dataset size is as below\n",
            "(8675, 595)\n",
            "10 feature names can be seen below\n",
            "[(0, 'ability'), (1, 'able'), (2, 'absolutely'), (3, 'across'), (4, 'act'), (5, 'action'), (6, 'actually'), (7, 'add'), (8, 'advice'), (9, 'afraid')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#counting top 50 words\n",
        "reverse_dic = {}\n",
        "for key in tfidf_vectorizer.vocabulary_:\n",
        "    reverse_dic[tfidf_vectorizer.vocabulary_[key]] = key\n",
        "top_50 = np.asarray(np.argsort(np.sum(X_tfidf, axis=0))[0,-50:][0, ::-1]).flatten()\n",
        "[reverse_dic[v] for v in top_50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xuhNgJC6PUre",
        "outputId": "ccd99809-9f43-4264-fc5d-f1812315086d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['type',\n",
              " 'feel',\n",
              " 'friend',\n",
              " 'love',\n",
              " 'well',\n",
              " 'say',\n",
              " 'want',\n",
              " 'way',\n",
              " 'good',\n",
              " 'something',\n",
              " 'see',\n",
              " 'also',\n",
              " 'lot',\n",
              " 'go',\n",
              " 'life',\n",
              " 'someone',\n",
              " 'always',\n",
              " 'even',\n",
              " 'year',\n",
              " 'never',\n",
              " 'could',\n",
              " 'though',\n",
              " 'find',\n",
              " 'thought',\n",
              " 'need',\n",
              " 'work',\n",
              " 'pretty',\n",
              " 'actually',\n",
              " 'person',\n",
              " 'yes',\n",
              " 'sure',\n",
              " 'going',\n",
              " 'right',\n",
              " 'first',\n",
              " 'day',\n",
              " 'feeling',\n",
              " 'thread',\n",
              " 'guy',\n",
              " 'mean',\n",
              " 'post',\n",
              " 'take',\n",
              " 'lol',\n",
              " 'come',\n",
              " 'still',\n",
              " 'said',\n",
              " 'look',\n",
              " 'got',\n",
              " 'many',\n",
              " 'read',\n",
              " 'relationship']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize personality types\n",
        "personality_type = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) / Sensing (S)\",\n",
        "                   \"FT: Feeling (F) / Thinking (T)\", \"JP: Judging (J) / Perceiving (P)\"  ]\n",
        "\n",
        "for l in range(len(personality_type)):\n",
        "    print(personality_type[l])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kqNg7v4PlF3",
        "outputId": "f6093d04-cc88-4f1b-da2f-22efe889a845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E)\n",
            "NS: Intuition (N) / Sensing (S)\n",
            "FT: Feeling (F) / Thinking (T)\n",
            "JP: Judging (J) / Perceiving (P)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X: 1st posts in tf-idf representation\\n%s\" % X_tfidf[0])\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dP1J3_arQA_5",
        "outputId": "224d167f-cb50-4edd-c26b-3f886af44ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: 1st posts in tf-idf representation\n",
            "  (0, 349)\t0.059410348139259946\n",
            "  (0, 489)\t0.06502346132069718\n",
            "  (0, 338)\t0.08813151493295181\n",
            "  (0, 565)\t0.041111781914928196\n",
            "  (0, 52)\t0.07087570430581895\n",
            "  (0, 51)\t0.05506308219879645\n",
            "  (0, 277)\t0.09349615314377653\n",
            "  (0, 481)\t0.07466644149972529\n",
            "  (0, 11)\t0.07066064469623083\n",
            "  (0, 590)\t0.04833236437892714\n",
            "  (0, 485)\t0.09843693837709419\n",
            "  (0, 10)\t0.0810547840560131\n",
            "  (0, 222)\t0.08435344092094439\n",
            "  (0, 340)\t0.07177947503220493\n",
            "  (0, 441)\t0.06318281551598931\n",
            "  (0, 366)\t0.06973745829337154\n",
            "  (0, 261)\t0.055577348034995554\n",
            "  (0, 457)\t0.08311160014717112\n",
            "  (0, 276)\t0.07930796829118913\n",
            "  (0, 433)\t0.08968055824148229\n",
            "  (0, 510)\t0.08067849379801398\n",
            "  (0, 406)\t0.09901670503451844\n",
            "  (0, 450)\t0.06642087294200923\n",
            "  (0, 383)\t0.09674118343306329\n",
            "  (0, 243)\t0.056315768105070226\n",
            "  :\t:\n",
            "  (0, 192)\t0.293044846811719\n",
            "  (0, 499)\t0.06869091772866434\n",
            "  (0, 568)\t0.1643469482973132\n",
            "  (0, 218)\t0.05834299082379839\n",
            "  (0, 171)\t0.08435344092094439\n",
            "  (0, 544)\t0.10580776947921257\n",
            "  (0, 148)\t0.05892624299511199\n",
            "  (0, 424)\t0.05873656603345169\n",
            "  (0, 343)\t0.09843693837709419\n",
            "  (0, 221)\t0.08003112352137877\n",
            "  (0, 480)\t0.06799660772948053\n",
            "  (0, 225)\t0.09115444123062892\n",
            "  (0, 429)\t0.09634949175630017\n",
            "  (0, 111)\t0.05133662207417498\n",
            "  (0, 350)\t0.0818801383450484\n",
            "  (0, 399)\t0.0899339569573682\n",
            "  (0, 185)\t0.04471931708869306\n",
            "  (0, 268)\t0.061134802272415925\n",
            "  (0, 316)\t0.05993985032654697\n",
            "  (0, 528)\t0.153384502207841\n",
            "  (0, 154)\t0.12451510375004599\n",
            "  (0, 285)\t0.13427658150846844\n",
            "  (0, 393)\t0.07446813831254685\n",
            "  (0, 533)\t0.09298479144475794\n",
            "  (0, 332)\t0.1534172565796732\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"For MBTI personality type : %s\" % translate_back(list_personality[0,:]))\n",
        "print(\"Y : Binarized MBTI 1st row: %s\" % list_personality[0,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkkmqJnnQG5a",
        "outputId": "37c2e485-30c3-4763-d918-030ccf1083b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For MBTI personality type : INFJ\n",
            "Y : Binarized MBTI 1st row: [0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_tfidf"
      ],
      "metadata": {
        "id": "UjCuA3a3QO7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Randomforest"
      ],
      "metadata": {
        "id": "CqNsLs5OQijY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to array if not already\n",
        "X = X_tfidf.toarray()\n",
        "\n",
        "# Loop through each personality type dimension\n",
        "for l in range(len(personality_type)):\n",
        "    Y = list_personality[:, l]\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Fit model on training data\n",
        "    model = RandomForestClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_Q2eGvWQy76",
        "outputId": "fbe04f9b-b58b-4701-a34d-b39835d73085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) Accuracy: 77.56%\n",
            "NS: Intuition (N) / Sensing (S) Accuracy: 85.52%\n",
            "FT: Feeling (F) / Thinking (T) Accuracy: 68.38%\n",
            "JP: Judging (J) / Perceiving (P) Accuracy: 62.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost model for MBTI dataset\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "\n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-IDHKpBQ1i2",
        "outputId": "230f4767-46ce-40d1-deb8-dbd18758665e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) Accuracy: 75.52%\n",
            "NS: Intuition (N) / Sensing (S) Accuracy: 85.19%\n",
            "FT: Feeling (F) / Thinking (T) Accuracy: 67.69%\n",
            "JP: Judging (J) / Perceiving (P) Accuracy: 61.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stocastic Gradient Descent for MBTI dataset\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "\n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = SGDClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO62Vo7wSXTe",
        "outputId": "45506765-b527-4a89-94e6-484f0124b04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) Accuracy: 77.54%\n",
            "NS: Intuition (N) / Sensing (S) Accuracy: 86.03%\n",
            "FT: Feeling (F) / Thinking (T) Accuracy: 72.34%\n",
            "JP: Judging (J) / Perceiving (P) Accuracy: 64.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression for MBTI dataset\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "\n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8YARm0vSykN",
        "outputId": "709fbc0d-0144-4c14-cc4c-67432ee19b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) Accuracy: 77.54%\n",
            "NS: Intuition (N) / Sensing (S) Accuracy: 86.06%\n",
            "FT: Feeling (F) / Thinking (T) Accuracy: 72.44%\n",
            "JP: Judging (J) / Perceiving (P) Accuracy: 64.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical  # Use to_categorical instead of np_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8zOUGALS7Jo",
        "outputId": "29d06467-8886-4ffd-d2c8-452a279d870c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create model\n",
        "def create_model(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "gUmyjjpyTyUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loop through each personality type dimension\n",
        "for l in range(len(personality_type)):\n",
        "    Y = list_personality[:, l]\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # Create model\n",
        "    model = create_model(X_train.shape[1])\n",
        "\n",
        "    # Fit model on training data\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1, validation_split=0.2)\n",
        "\n",
        "    # Make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    predictions = [round(value[0]) for value in y_pred]\n",
        "\n",
        "    # Evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbCpcrpGUk8u",
        "outputId": "d7435a5c-8d7d-484d-c0cc-24b853773a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.7469 - loss: 0.5776 - val_accuracy: 0.7635 - val_loss: 0.5401\n",
            "Epoch 2/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7630 - loss: 0.5200 - val_accuracy: 0.7635 - val_loss: 0.5209\n",
            "Epoch 3/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7767 - loss: 0.4580 - val_accuracy: 0.7601 - val_loss: 0.5461\n",
            "Epoch 4/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8047 - loss: 0.4257 - val_accuracy: 0.7403 - val_loss: 0.5683\n",
            "Epoch 5/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8660 - loss: 0.3392 - val_accuracy: 0.7137 - val_loss: 0.6183\n",
            "Epoch 6/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9219 - loss: 0.2283 - val_accuracy: 0.6827 - val_loss: 0.7326\n",
            "Epoch 7/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9662 - loss: 0.1195 - val_accuracy: 0.7266 - val_loss: 0.9950\n",
            "Epoch 8/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9894 - loss: 0.0445 - val_accuracy: 0.7163 - val_loss: 1.1141\n",
            "Epoch 9/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9922 - loss: 0.0230 - val_accuracy: 0.6982 - val_loss: 1.2607\n",
            "Epoch 10/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9928 - loss: 0.0144 - val_accuracy: 0.7111 - val_loss: 1.4038\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "IE: Introversion (I) / Extroversion (E) Accuracy: 71.71%\n",
            "Epoch 1/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8200 - loss: 0.5165 - val_accuracy: 0.8624 - val_loss: 0.4070\n",
            "Epoch 2/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8669 - loss: 0.3888 - val_accuracy: 0.8624 - val_loss: 0.3940\n",
            "Epoch 3/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8712 - loss: 0.3442 - val_accuracy: 0.8624 - val_loss: 0.3984\n",
            "Epoch 4/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8644 - loss: 0.3153 - val_accuracy: 0.8624 - val_loss: 0.4240\n",
            "Epoch 5/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8830 - loss: 0.2743 - val_accuracy: 0.8461 - val_loss: 0.4808\n",
            "Epoch 6/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9283 - loss: 0.1971 - val_accuracy: 0.8383 - val_loss: 0.5272\n",
            "Epoch 7/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9584 - loss: 0.1336 - val_accuracy: 0.8358 - val_loss: 0.6455\n",
            "Epoch 8/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9865 - loss: 0.0602 - val_accuracy: 0.8186 - val_loss: 0.7649\n",
            "Epoch 9/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9971 - loss: 0.0196 - val_accuracy: 0.8212 - val_loss: 0.8877\n",
            "Epoch 10/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9989 - loss: 0.0110 - val_accuracy: 0.8289 - val_loss: 1.0076\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "NS: Intuition (N) / Sensing (S) Accuracy: 83.06%\n",
            "Epoch 1/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5939 - loss: 0.6679 - val_accuracy: 0.7154 - val_loss: 0.5606\n",
            "Epoch 2/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7695 - loss: 0.4922 - val_accuracy: 0.7231 - val_loss: 0.5553\n",
            "Epoch 3/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7908 - loss: 0.4513 - val_accuracy: 0.7248 - val_loss: 0.5756\n",
            "Epoch 4/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8200 - loss: 0.4106 - val_accuracy: 0.6982 - val_loss: 0.6168\n",
            "Epoch 5/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8655 - loss: 0.3408 - val_accuracy: 0.7034 - val_loss: 0.6436\n",
            "Epoch 6/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9187 - loss: 0.2513 - val_accuracy: 0.6973 - val_loss: 0.7811\n",
            "Epoch 7/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9669 - loss: 0.1214 - val_accuracy: 0.6939 - val_loss: 0.8989\n",
            "Epoch 8/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9873 - loss: 0.0505 - val_accuracy: 0.6862 - val_loss: 1.0593\n",
            "Epoch 9/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9929 - loss: 0.0243 - val_accuracy: 0.6896 - val_loss: 1.2374\n",
            "Epoch 10/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.0147 - val_accuracy: 0.6896 - val_loss: 1.3353\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "FT: Feeling (F) / Thinking (T) Accuracy: 69.16%\n",
            "Epoch 1/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5965 - loss: 0.6774 - val_accuracy: 0.5821 - val_loss: 0.6707\n",
            "Epoch 2/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6173 - loss: 0.6389 - val_accuracy: 0.6019 - val_loss: 0.6573\n",
            "Epoch 3/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7107 - loss: 0.5742 - val_accuracy: 0.6062 - val_loss: 0.6690\n",
            "Epoch 4/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7575 - loss: 0.5108 - val_accuracy: 0.6002 - val_loss: 0.7035\n",
            "Epoch 5/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 0.3989 - val_accuracy: 0.5942 - val_loss: 0.8255\n",
            "Epoch 6/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9394 - loss: 0.2195 - val_accuracy: 0.5873 - val_loss: 1.1131\n",
            "Epoch 7/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0792 - val_accuracy: 0.5924 - val_loss: 1.3330\n",
            "Epoch 8/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0317 - val_accuracy: 0.5838 - val_loss: 1.5260\n",
            "Epoch 9/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0160 - val_accuracy: 0.5959 - val_loss: 1.6311\n",
            "Epoch 10/10\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0114 - val_accuracy: 0.6088 - val_loss: 1.7698\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "JP: Judging (J) / Perceiving (P) Accuracy: 61.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "import keras_tuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=hp.Int('units_input', min_value=32, max_value=256, step=32), input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(units=hp.Int('units_hidden1', min_value=32, max_value=256, step=32), activation='relu'))\n",
        "    model.add(Dense(units=hp.Int('units_hidden2', min_value=32, max_value=256, step=32), activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Loop through each personality type dimension\n",
        "for l in range(len(personality_type)):\n",
        "    Y = list_personality[:, l]\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "    # Hyperparameter tuner\n",
        "    tuner = kt.Hyperband(\n",
        "        build_model,\n",
        "        objective='val_accuracy',\n",
        "        max_epochs=20,\n",
        "        factor=3,\n",
        "        directory='my_dir',\n",
        "        project_name='mbti_personality'\n",
        "    )\n",
        "\n",
        "    # Search for best hyperparameters\n",
        "    tuner.search(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
        "\n",
        "    # Get the optimal hyperparameters\n",
        "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "    # Build the model with the optimal hyperparameters and train it\n",
        "    model = tuner.hypermodel.build(best_hps)\n",
        "    history = model.fit(X_train, y_train, epochs=50, validation_split=0.2, verbose=1)\n",
        "\n",
        "    # Make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    predictions = [round(value[0]) for value in y_pred]\n",
        "\n",
        "    # Evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccE0xeE8WcfX",
        "outputId": "e5043dd6-29d7-4b1c-b746-3eedf66143a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 19s]\n",
            "val_accuracy: 0.7635425329208374\n",
            "\n",
            "Best val_accuracy So Far: 0.7644023895263672\n",
            "Total elapsed time: 00h 05m 18s\n",
            "Epoch 1/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7326 - loss: 0.5697 - val_accuracy: 0.7635 - val_loss: 0.5241\n",
            "Epoch 2/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.4821 - val_accuracy: 0.7644 - val_loss: 0.5515\n",
            "Epoch 3/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7895 - loss: 0.4332 - val_accuracy: 0.7395 - val_loss: 0.5558\n",
            "Epoch 4/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.3459 - val_accuracy: 0.7206 - val_loss: 0.6298\n",
            "Epoch 5/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9345 - loss: 0.1874 - val_accuracy: 0.7549 - val_loss: 0.8700\n",
            "Epoch 6/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9777 - loss: 0.0685 - val_accuracy: 0.6767 - val_loss: 1.1210\n",
            "Epoch 7/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0261 - val_accuracy: 0.7334 - val_loss: 1.3778\n",
            "Epoch 8/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9931 - loss: 0.0159 - val_accuracy: 0.7326 - val_loss: 1.5147\n",
            "Epoch 9/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0106 - val_accuracy: 0.7455 - val_loss: 1.6691\n",
            "Epoch 10/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0126 - val_accuracy: 0.7248 - val_loss: 1.6176\n",
            "Epoch 11/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0100 - val_accuracy: 0.7377 - val_loss: 1.7370\n",
            "Epoch 12/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0117 - val_accuracy: 0.7481 - val_loss: 1.8117\n",
            "Epoch 13/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0090 - val_accuracy: 0.7412 - val_loss: 1.7890\n",
            "Epoch 14/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0104 - val_accuracy: 0.7369 - val_loss: 1.7888\n",
            "Epoch 15/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0093 - val_accuracy: 0.7386 - val_loss: 1.7966\n",
            "Epoch 16/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0087 - val_accuracy: 0.7360 - val_loss: 1.8010\n",
            "Epoch 17/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0097 - val_accuracy: 0.7137 - val_loss: 1.7425\n",
            "Epoch 18/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0074 - val_accuracy: 0.7266 - val_loss: 1.7919\n",
            "Epoch 19/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0095 - val_accuracy: 0.7283 - val_loss: 1.8567\n",
            "Epoch 20/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0092 - val_accuracy: 0.7240 - val_loss: 1.8503\n",
            "Epoch 21/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0104 - val_accuracy: 0.7283 - val_loss: 1.8483\n",
            "Epoch 22/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0081 - val_accuracy: 0.7223 - val_loss: 1.8353\n",
            "Epoch 23/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0115 - val_accuracy: 0.7197 - val_loss: 1.8349\n",
            "Epoch 24/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0103 - val_accuracy: 0.7317 - val_loss: 1.9042\n",
            "Epoch 25/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0100 - val_accuracy: 0.7386 - val_loss: 1.9518\n",
            "Epoch 26/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0099 - val_accuracy: 0.7240 - val_loss: 1.8704\n",
            "Epoch 27/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0106 - val_accuracy: 0.7223 - val_loss: 1.8021\n",
            "Epoch 28/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0095 - val_accuracy: 0.7214 - val_loss: 1.8562\n",
            "Epoch 29/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0086 - val_accuracy: 0.7334 - val_loss: 1.9448\n",
            "Epoch 30/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 0.0089 - val_accuracy: 0.7231 - val_loss: 1.9503\n",
            "Epoch 31/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0103 - val_accuracy: 0.7309 - val_loss: 2.0177\n",
            "Epoch 32/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0114 - val_accuracy: 0.7360 - val_loss: 2.1120\n",
            "Epoch 33/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0112 - val_accuracy: 0.7326 - val_loss: 2.0840\n",
            "Epoch 34/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0084 - val_accuracy: 0.7334 - val_loss: 2.0670\n",
            "Epoch 35/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0087 - val_accuracy: 0.7386 - val_loss: 2.1493\n",
            "Epoch 36/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0100 - val_accuracy: 0.7317 - val_loss: 2.1283\n",
            "Epoch 37/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0077 - val_accuracy: 0.7352 - val_loss: 2.1966\n",
            "Epoch 38/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0075 - val_accuracy: 0.7395 - val_loss: 2.2724\n",
            "Epoch 39/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0089 - val_accuracy: 0.7326 - val_loss: 2.2301\n",
            "Epoch 40/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0098 - val_accuracy: 0.7395 - val_loss: 2.3420\n",
            "Epoch 41/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0070 - val_accuracy: 0.7309 - val_loss: 2.2531\n",
            "Epoch 42/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0107 - val_accuracy: 0.7369 - val_loss: 2.3606\n",
            "Epoch 43/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0096 - val_accuracy: 0.7360 - val_loss: 2.3262\n",
            "Epoch 44/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.0110 - val_accuracy: 0.7369 - val_loss: 2.3922\n",
            "Epoch 45/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0108 - val_accuracy: 0.7377 - val_loss: 2.4476\n",
            "Epoch 46/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0091 - val_accuracy: 0.7334 - val_loss: 2.4414\n",
            "Epoch 47/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0091 - val_accuracy: 0.7412 - val_loss: 2.5376\n",
            "Epoch 48/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0079 - val_accuracy: 0.7377 - val_loss: 2.6348\n",
            "Epoch 49/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0072 - val_accuracy: 0.7395 - val_loss: 2.4846\n",
            "Epoch 50/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0100 - val_accuracy: 0.7377 - val_loss: 2.5267\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "I/E Accuracy: 73.31%\n",
            "Reloading Tuner from my_dir/mbti_personality/tuner0.json\n",
            "Epoch 1/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.4915 - val_accuracy: 0.8624 - val_loss: 0.4010\n",
            "Epoch 2/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8661 - loss: 0.3751 - val_accuracy: 0.8624 - val_loss: 0.3936\n",
            "Epoch 3/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8549 - loss: 0.3404 - val_accuracy: 0.8624 - val_loss: 0.4545\n",
            "Epoch 4/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8745 - loss: 0.2698 - val_accuracy: 0.8607 - val_loss: 0.4808\n",
            "Epoch 5/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9085 - loss: 0.2254 - val_accuracy: 0.7567 - val_loss: 0.5731\n",
            "Epoch 6/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1246 - val_accuracy: 0.8014 - val_loss: 0.6842\n",
            "Epoch 7/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0468 - val_accuracy: 0.8203 - val_loss: 0.8939\n",
            "Epoch 8/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0138 - val_accuracy: 0.8169 - val_loss: 1.0828\n",
            "Epoch 9/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0041 - val_accuracy: 0.8323 - val_loss: 1.2141\n",
            "Epoch 10/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.8315 - val_loss: 1.2696\n",
            "Epoch 11/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.8151 - val_loss: 1.2117\n",
            "Epoch 12/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0054 - val_accuracy: 0.8255 - val_loss: 1.2914\n",
            "Epoch 13/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0065 - val_accuracy: 0.8280 - val_loss: 1.2990\n",
            "Epoch 14/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0053 - val_accuracy: 0.8212 - val_loss: 1.2992\n",
            "Epoch 15/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.8177 - val_loss: 1.3065\n",
            "Epoch 16/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.8229 - val_loss: 1.3283\n",
            "Epoch 17/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0040 - val_accuracy: 0.8194 - val_loss: 1.2973\n",
            "Epoch 18/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 0.8246 - val_loss: 1.3342\n",
            "Epoch 19/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.8220 - val_loss: 1.3513\n",
            "Epoch 20/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.8255 - val_loss: 1.3572\n",
            "Epoch 21/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0024 - val_accuracy: 0.8255 - val_loss: 1.3580\n",
            "Epoch 22/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.8315 - val_loss: 1.4371\n",
            "Epoch 23/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 0.8203 - val_loss: 1.3574\n",
            "Epoch 24/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0040 - val_accuracy: 0.8237 - val_loss: 1.3892\n",
            "Epoch 25/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.8323 - val_loss: 1.4841\n",
            "Epoch 26/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0065 - val_accuracy: 0.8280 - val_loss: 1.4572\n",
            "Epoch 27/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.8246 - val_loss: 1.4610\n",
            "Epoch 28/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.8220 - val_loss: 1.4505\n",
            "Epoch 29/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.8194 - val_loss: 1.4308\n",
            "Epoch 30/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 0.8280 - val_loss: 1.4838\n",
            "Epoch 31/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.8289 - val_loss: 1.4853\n",
            "Epoch 32/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.8151 - val_loss: 1.4429\n",
            "Epoch 33/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0042 - val_accuracy: 0.8298 - val_loss: 1.5734\n",
            "Epoch 34/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.8212 - val_loss: 1.5009\n",
            "Epoch 35/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.8280 - val_loss: 1.5394\n",
            "Epoch 36/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0050 - val_accuracy: 0.8229 - val_loss: 1.5656\n",
            "Epoch 37/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0070 - val_accuracy: 0.8306 - val_loss: 1.5558\n",
            "Epoch 38/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.8298 - val_loss: 1.5946\n",
            "Epoch 39/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0049 - val_accuracy: 0.8306 - val_loss: 1.6093\n",
            "Epoch 40/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.8306 - val_loss: 1.5758\n",
            "Epoch 41/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.8237 - val_loss: 1.5435\n",
            "Epoch 42/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.8306 - val_loss: 1.6207\n",
            "Epoch 43/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.8298 - val_loss: 1.6221\n",
            "Epoch 44/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.8315 - val_loss: 1.6079\n",
            "Epoch 45/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.8306 - val_loss: 1.6261\n",
            "Epoch 46/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.8289 - val_loss: 1.5770\n",
            "Epoch 47/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.8280 - val_loss: 1.5077\n",
            "Epoch 48/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.8306 - val_loss: 1.6190\n",
            "Epoch 49/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.8212 - val_loss: 1.6986\n",
            "Epoch 50/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.8298 - val_loss: 1.6036\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "N/S Accuracy: 83.02%\n",
            "Reloading Tuner from my_dir/mbti_personality/tuner0.json\n",
            "Epoch 1/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5995 - loss: 0.6562 - val_accuracy: 0.7240 - val_loss: 0.5515\n",
            "Epoch 2/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7489 - loss: 0.5001 - val_accuracy: 0.6965 - val_loss: 0.5741\n",
            "Epoch 3/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.4559 - val_accuracy: 0.7145 - val_loss: 0.5758\n",
            "Epoch 4/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8412 - loss: 0.3808 - val_accuracy: 0.7085 - val_loss: 0.6334\n",
            "Epoch 5/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.2685 - val_accuracy: 0.6819 - val_loss: 0.7745\n",
            "Epoch 6/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.1189 - val_accuracy: 0.6741 - val_loss: 0.9980\n",
            "Epoch 7/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0419 - val_accuracy: 0.6733 - val_loss: 1.2559\n",
            "Epoch 8/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0196 - val_accuracy: 0.6836 - val_loss: 1.4309\n",
            "Epoch 9/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0119 - val_accuracy: 0.6862 - val_loss: 1.6000\n",
            "Epoch 10/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0104 - val_accuracy: 0.6887 - val_loss: 1.6587\n",
            "Epoch 11/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0108 - val_accuracy: 0.6879 - val_loss: 1.6621\n",
            "Epoch 12/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0113 - val_accuracy: 0.6853 - val_loss: 1.7382\n",
            "Epoch 13/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0106 - val_accuracy: 0.6844 - val_loss: 1.7834\n",
            "Epoch 14/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0132 - val_accuracy: 0.6784 - val_loss: 1.7857\n",
            "Epoch 15/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0095 - val_accuracy: 0.6853 - val_loss: 1.8475\n",
            "Epoch 16/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0079 - val_accuracy: 0.6767 - val_loss: 1.8410\n",
            "Epoch 17/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9937 - loss: 0.0102 - val_accuracy: 0.6836 - val_loss: 1.9231\n",
            "Epoch 18/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0080 - val_accuracy: 0.6819 - val_loss: 1.9495\n",
            "Epoch 19/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0074 - val_accuracy: 0.6801 - val_loss: 1.9772\n",
            "Epoch 20/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0079 - val_accuracy: 0.6776 - val_loss: 2.0040\n",
            "Epoch 21/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0071 - val_accuracy: 0.6801 - val_loss: 2.0189\n",
            "Epoch 22/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0077 - val_accuracy: 0.6810 - val_loss: 2.0406\n",
            "Epoch 23/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0090 - val_accuracy: 0.6810 - val_loss: 2.1124\n",
            "Epoch 24/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0073 - val_accuracy: 0.6810 - val_loss: 2.1330\n",
            "Epoch 25/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0080 - val_accuracy: 0.6819 - val_loss: 2.1882\n",
            "Epoch 26/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0083 - val_accuracy: 0.6827 - val_loss: 2.2142\n",
            "Epoch 27/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0088 - val_accuracy: 0.6844 - val_loss: 2.2044\n",
            "Epoch 28/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0081 - val_accuracy: 0.6793 - val_loss: 2.2361\n",
            "Epoch 29/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0076 - val_accuracy: 0.6776 - val_loss: 2.2500\n",
            "Epoch 30/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0078 - val_accuracy: 0.6793 - val_loss: 2.2997\n",
            "Epoch 31/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0071 - val_accuracy: 0.6793 - val_loss: 2.3231\n",
            "Epoch 32/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0090 - val_accuracy: 0.6793 - val_loss: 2.3292\n",
            "Epoch 33/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0086 - val_accuracy: 0.6776 - val_loss: 2.3415\n",
            "Epoch 34/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0074 - val_accuracy: 0.6793 - val_loss: 2.3731\n",
            "Epoch 35/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 0.0071 - val_accuracy: 0.6801 - val_loss: 2.3829\n",
            "Epoch 36/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0077 - val_accuracy: 0.6750 - val_loss: 2.3907\n",
            "Epoch 37/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0079 - val_accuracy: 0.6767 - val_loss: 2.4001\n",
            "Epoch 38/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0072 - val_accuracy: 0.6784 - val_loss: 2.4422\n",
            "Epoch 39/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0080 - val_accuracy: 0.6793 - val_loss: 2.4588\n",
            "Epoch 40/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0064 - val_accuracy: 0.6784 - val_loss: 2.4795\n",
            "Epoch 41/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0102 - val_accuracy: 0.6810 - val_loss: 2.5231\n",
            "Epoch 42/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0083 - val_accuracy: 0.6758 - val_loss: 2.5290\n",
            "Epoch 43/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0073 - val_accuracy: 0.6853 - val_loss: 2.5811\n",
            "Epoch 44/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0074 - val_accuracy: 0.6810 - val_loss: 2.5768\n",
            "Epoch 45/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0108 - val_accuracy: 0.6801 - val_loss: 2.6374\n",
            "Epoch 46/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0065 - val_accuracy: 0.6793 - val_loss: 2.6082\n",
            "Epoch 47/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0072 - val_accuracy: 0.6784 - val_loss: 2.6419\n",
            "Epoch 48/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0081 - val_accuracy: 0.6793 - val_loss: 2.6744\n",
            "Epoch 49/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0082 - val_accuracy: 0.6870 - val_loss: 2.7365\n",
            "Epoch 50/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0077 - val_accuracy: 0.6776 - val_loss: 2.7222\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "F/T Accuracy: 69.40%\n",
            "Reloading Tuner from my_dir/mbti_personality/tuner0.json\n",
            "Epoch 1/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5910 - loss: 0.6755 - val_accuracy: 0.5847 - val_loss: 0.6803\n",
            "Epoch 2/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6543 - loss: 0.6207 - val_accuracy: 0.5890 - val_loss: 0.6791\n",
            "Epoch 3/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7249 - loss: 0.5481 - val_accuracy: 0.5993 - val_loss: 0.7439\n",
            "Epoch 4/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7995 - loss: 0.4450 - val_accuracy: 0.6036 - val_loss: 0.8022\n",
            "Epoch 5/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.2421 - val_accuracy: 0.5770 - val_loss: 1.0151\n",
            "Epoch 6/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9757 - loss: 0.0953 - val_accuracy: 0.5752 - val_loss: 1.4190\n",
            "Epoch 7/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0295 - val_accuracy: 0.5727 - val_loss: 1.8124\n",
            "Epoch 8/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0166 - val_accuracy: 0.5847 - val_loss: 2.0204\n",
            "Epoch 9/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0169 - val_accuracy: 0.5821 - val_loss: 2.0575\n",
            "Epoch 10/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0094 - val_accuracy: 0.5830 - val_loss: 2.1310\n",
            "Epoch 11/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0103 - val_accuracy: 0.5838 - val_loss: 2.2802\n",
            "Epoch 12/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0107 - val_accuracy: 0.5838 - val_loss: 2.2091\n",
            "Epoch 13/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0076 - val_accuracy: 0.5873 - val_loss: 2.2555\n",
            "Epoch 14/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0083 - val_accuracy: 0.5856 - val_loss: 2.2085\n",
            "Epoch 15/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.5847 - val_loss: 2.2094\n",
            "Epoch 16/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0098 - val_accuracy: 0.5787 - val_loss: 2.3568\n",
            "Epoch 17/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0123 - val_accuracy: 0.5873 - val_loss: 2.2762\n",
            "Epoch 18/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0079 - val_accuracy: 0.5830 - val_loss: 2.3581\n",
            "Epoch 19/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0111 - val_accuracy: 0.5830 - val_loss: 2.3363\n",
            "Epoch 20/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0110 - val_accuracy: 0.5899 - val_loss: 2.2853\n",
            "Epoch 21/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0083 - val_accuracy: 0.5890 - val_loss: 2.3314\n",
            "Epoch 22/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0072 - val_accuracy: 0.5847 - val_loss: 2.3008\n",
            "Epoch 23/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0117 - val_accuracy: 0.5813 - val_loss: 2.2971\n",
            "Epoch 24/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0098 - val_accuracy: 0.5838 - val_loss: 2.2581\n",
            "Epoch 25/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0105 - val_accuracy: 0.5873 - val_loss: 2.3167\n",
            "Epoch 26/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0086 - val_accuracy: 0.5881 - val_loss: 2.3488\n",
            "Epoch 27/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0082 - val_accuracy: 0.5907 - val_loss: 2.3531\n",
            "Epoch 28/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0086 - val_accuracy: 0.5890 - val_loss: 2.3908\n",
            "Epoch 29/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0074 - val_accuracy: 0.5864 - val_loss: 2.4166\n",
            "Epoch 30/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0094 - val_accuracy: 0.5873 - val_loss: 2.4373\n",
            "Epoch 31/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0083 - val_accuracy: 0.5907 - val_loss: 2.4820\n",
            "Epoch 32/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0102 - val_accuracy: 0.5881 - val_loss: 2.4781\n",
            "Epoch 33/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0077 - val_accuracy: 0.5899 - val_loss: 2.4709\n",
            "Epoch 34/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0073 - val_accuracy: 0.5890 - val_loss: 2.4719\n",
            "Epoch 35/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0076 - val_accuracy: 0.5838 - val_loss: 2.5139\n",
            "Epoch 36/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0079 - val_accuracy: 0.5916 - val_loss: 2.5106\n",
            "Epoch 37/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0083 - val_accuracy: 0.5899 - val_loss: 2.5744\n",
            "Epoch 38/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0088 - val_accuracy: 0.5907 - val_loss: 2.5198\n",
            "Epoch 39/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0095 - val_accuracy: 0.5907 - val_loss: 2.5572\n",
            "Epoch 40/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0089 - val_accuracy: 0.5959 - val_loss: 2.7146\n",
            "Epoch 41/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0056 - val_accuracy: 0.5924 - val_loss: 2.6113\n",
            "Epoch 42/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9957 - loss: 0.0078 - val_accuracy: 0.5907 - val_loss: 2.6337\n",
            "Epoch 43/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0107 - val_accuracy: 0.5899 - val_loss: 2.7159\n",
            "Epoch 44/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0061 - val_accuracy: 0.5890 - val_loss: 2.6850\n",
            "Epoch 45/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0048 - val_accuracy: 0.5907 - val_loss: 2.7085\n",
            "Epoch 46/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0077 - val_accuracy: 0.5890 - val_loss: 2.6945\n",
            "Epoch 47/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0077 - val_accuracy: 0.5950 - val_loss: 2.7166\n",
            "Epoch 48/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0080 - val_accuracy: 0.5950 - val_loss: 2.7662\n",
            "Epoch 49/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0070 - val_accuracy: 0.5924 - val_loss: 2.7705\n",
            "Epoch 50/50\n",
            "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0071 - val_accuracy: 0.5950 - val_loss: 2.9347\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "J/P Accuracy: 62.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup parameters for xgboost\n",
        "param = {}\n",
        "\n",
        "param['n_estimators'] = 200 #100\n",
        "param['max_depth'] = 2 #3\n",
        "param['nthread'] = 8 #1\n",
        "param['learning_rate'] = 0.2 #0.1\n",
        "\n",
        "# Individually training each mbti personlity type\n",
        "for l in range(len(personality_type)):\n",
        "    Y = list_personality[:,l]\n",
        "\n",
        "    # split data into train and test sets\n",
        "    seed = 7\n",
        "    test_size = 0.33\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "\n",
        "    # fit model on training data\n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train, y_train)\n",
        "    # make predictions for test data\n",
        "    y_pred = model.predict(X_test)\n",
        "    predictions = [round(value) for value in y_pred]\n",
        "    # evaluate predictions\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVyjW8tOWh7d",
        "outputId": "73975142-2e95-4c3c-a12f-ec30352d24a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IE: Introversion (I) / Extroversion (E) Accuracy: 77.02%\n",
            "NS: Intuition (N) / Sensing (S) Accuracy: 85.96%\n",
            "FT: Feeling (F) / Thinking (T) Accuracy: 69.68%\n",
            "JP: Judging (J) / Perceiving (P) Accuracy: 63.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RtMbWJ3dA0Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_posts = \"\"\" They act like they care They tell me to share But when I carve the stories on my arm The doctor just calls it self harm I’m not asking for attention There’s a reason I have apprehensions I just need you to see What has become of me||| I know I’m going crazy But they think my thoughts are just hazy When in that chaos, in that confusion I’m crying out for help, to escape my delusions||| Mental health is a state of mind How does one keep that up when assistance is denied All my failed attempts to fight the blaze You treat it like its a passing phase||| Well stop, its not, because mental illness is real Understand that we’re all not made of steel Because when you brush these issues under the carpet You make it seem like its our mistake we’re not guarded||| Don’t you realise that its a problem that needs to be addressed Starting at home, in our nest Why do you keep your mouths shut about such things Instead of caring for those with broken wings||| What use is this social stigma When mental illness is not even such an enigma Look around and you’ll see the numbers of the affected hiding under the covers ||| This is an issue that needs to be discussed Not looked down upon with disgust Mental illness needs to be accepted So that people can be protected ||| Let me give you some direction People need affection The darkness must be escaped Only then the lost can be saved||| Bring in a change Something not very strange The new year is here Its time to eradicate fear||| Recognise the wrists under the knives To stop mental illness from taking more lives Let’s break the convention Start ‘suicide prevention’.||| Hoping the festival of lights drives the darkness of mental illness away\"\"\""
      ],
      "metadata": {
        "id": "1rFxjrk_57D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame for the new data\n",
        "mydata = pd.DataFrame(data={'type': ['INFP'], 'posts': [my_posts]})\n",
        "\n",
        "# Preprocess the new data\n",
        "my_posts_processed, dummy = pre_process_text(mydata, remove_stop_words=True, remove_mbti_profiles=True)\n",
        "\n",
        "# Transform the new preprocessed posts using the same TfidfVectorizer used earlier\n",
        "# Note: Use the existing 'tfidf_vectorizer' from the previous code without fitting it again\n",
        "my_X_tfidf = tfidf_vectorizer.transform(my_posts_processed).toarray()\n",
        "\n",
        "print(\"Transformed new data:\")\n",
        "print(my_X_tfidf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ZrDkg11v7FoC",
        "outputId": "d32b266d-5c8c-4905-c9e2-efa9ee81927d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cannot use a string pattern on a bytes-like object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ac7128f62fa9>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Preprocess the new data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmy_posts_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_process_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_stop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_mbti_profiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Transform the new preprocessed posts using the same TfidfVectorizer used earlier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e54e596f2598>\u001b[0m in \u001b[0;36mpre_process_text\u001b[0;34m(data, remove_stop_words, remove_mbti_profiles)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Remove url links\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Remove Non-words - keep only words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TY7FHd-s7jwc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}